[
  {
    "name": "naive_default",
    "rag_type": "naive",
    "llm_provider": "openai",
    "llm_model": "gpt-4o-mini",
    "temperature": 1.0,
    "max_tokens": 512,
    "naive": {
      "chunk_documents": false,
      "embedding_model": "text-embedding-3-small",
      "k_retrieve": 10,
      "use_reranker": false,
      "max_docs": 10
    }
  },
  {
    "name": "naive_reranker",
    "rag_type": "naive",
    "llm_provider": "openai",
    "llm_model": "gpt-4o-mini",
    "temperature": 1.0,
    "max_tokens": 512,
    "naive": {
      "chunk_documents": false,
      "embedding_model": "text-embedding-3-small",
      "k_retrieve": 10,
      "use_reranker": true,
      "reranker_model": "BAAI/bge-reranker-base",
      "rerank_threshold": 0.5,
      "max_docs": 10
    }
  },
  {
    "name": "graphrag_local",
    "rag_type": "graphrag",
    "llm_provider": "openai",
    "llm_model": "gpt-4o-mini",
    "temperature": 1.0,
    "max_tokens": 512,
    "graphrag": {
      "indexing": {
        "cache_dir": "./graphrag_cache",
        "max_parallel_insert": 4,
        "batch_size": 128,
        "force_reindex": false,
        "inline_metadata": false
      },
      "query": {
        "mode": "local",
        "top_k": 50
      }
    }
  },
  {
    "name": "graphrag_hybrid",
    "rag_type": "graphrag",
    "llm_provider": "openai",
    "llm_model": "gpt-4o-mini",
    "temperature": 1.0,
    "max_tokens": 512,
    "graphrag": {
      "indexing": {
        "cache_dir": "./graphrag_cache",
        "max_parallel_insert": 4,
        "batch_size": 128,
        "force_reindex": false,
        "inline_metadata": false
      },
      "query": {
        "mode": "hybrid",
        "top_k": 50
      }
    }
  }
  
]
