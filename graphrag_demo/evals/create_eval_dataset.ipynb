{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from typing import Optional, List, Tuple\n",
        "import json\n",
        "import datasets\n",
        "import random\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Import from helpers\n",
        "from rag_helpers import (\n",
        "    read_jsonl,\n",
        "    write_jsonl,\n",
        "    write_csv,\n",
        "    to_serializable,\n",
        "    call_llm,\n",
        "    QA_generation_prompt,\n",
        "    question_groundedness_critique_prompt,\n",
        "    question_relevance_critique_prompt,\n",
        "    question_standalone_critique_prompt,\n",
        ")\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=500,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YErqpfH9jVI"
      },
      "source": [
        "# RAG Evaluation\n",
        "_Authored by: [Aymeric Roucher](https://huggingface.co/m-ric)_\n",
        "\n",
        "This notebook demonstrates how you can evaluate your RAG (Retrieval Augmented Generation), by building a synthetic evaluation dataset and using LLM-as-a-judge to compute the accuracy of your system.\n",
        "\n",
        "For an introduction to RAG, you can check [this other cookbook](rag_zephyr_langchain)!\n",
        "\n",
        "RAG systems are complex: here a RAG diagram, where we noted in blue all possibilities for system enhancement:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/RAG_workflow.png\" height=\"700\">\n",
        "\n",
        "Implementing any of these improvements can bring a huge performance boost; but changing anything is useless if you cannot monitor the impact of your changes on the system's performance!\n",
        "So let's see how to evaluate our RAG system.\n",
        "\n",
        "### Evaluating RAG performance\n",
        "\n",
        "Since there are so many moving parts to tune with a big impact on performance, benchmarking the RAG system is crucial.\n",
        "\n",
        "For our evaluation pipeline, we will need:\n",
        "1. An evaluation dataset with question - answer couples (QA couples)\n",
        "2. An evaluator to compute the accuracy of our system on the above evaluation dataset.\n",
        "\n",
        "‚û°Ô∏è It turns out, we can use LLMs to help us all along the way!\n",
        "1. The evaluation dataset will be synthetically generated by an LLM ü§ñ, and questions will be filtered out by other LLMs ü§ñ\n",
        "2. An [LLM-as-a-judge](https://huggingface.co/papers/2306.05685) agent ü§ñ will then perform the evaluation on this synthetic dataset.\n",
        "\n",
        "__Let's dig into it and start building our evaluation pipeline!__ First, we install the required model dependancies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bCKBvOcp9jVK"
      },
      "outputs": [],
      "source": [
        "# !pip install -q torch transformers langchain sentence-transformers tqdm openpyxl openai pandas datasets langchain-community ragatouille"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k_lJFbYm9jVL"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oIlNZ1Mn9jVL"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from typing import Optional, List, Tuple\n",
        "import json\n",
        "import datasets\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4ff_mr3lBMUc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffafa3b2437b4d61b738de049995eba8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeW8P62J9jVM"
      },
      "source": [
        "### Load your knowledge base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YRbm5tNF9jVM"
      },
      "outputs": [],
      "source": [
        "# download the dataset from the hub\n",
        "ds = datasets.load_dataset(\n",
        "    \"m-ric/huggingface_doc\", split=\"train\"\n",
        ")\n",
        "\n",
        "# ds = datasets.load_dataset(\n",
        "#     \"json\",\n",
        "#     data_files=str(save_dir / \"initial_corpus.jsonl\"),\n",
        "#     split=\"train\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'source'],\n",
            "    num_rows: 2647\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy9CKj0M9jVM"
      },
      "source": [
        "# 1. Build a synthetic dataset for evaluation\n",
        "We first build a synthetic dataset of questions and associated contexts. The method is to get elements from our knowledge base, and ask an LLM to generate questions based on these documents.\n",
        "\n",
        "Then we setup other LLM agents to act as quality filters for the generated QA couples: each of them will act as the filter for a specific flaw."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkoEgiDg9jVM"
      },
      "source": [
        "### 1.1. Prepare source documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3gTOlRKO9jVM"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87b40936dce649e8ad06443f9ff0b5fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "\n",
        "langchain_docs = [\n",
        "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
        "    for doc in tqdm(ds)\n",
        "]\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=200,\n",
        "    add_start_index=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "docs_processed = []\n",
        "for doc in langchain_docs:\n",
        "    docs_processed += text_splitter.split_documents([doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjrNhcCh9jVN"
      },
      "source": [
        "### 1.2. Setup agents for question generation\n",
        "\n",
        "We use [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) for QA couple generation because it it has excellent performance in leaderboards such as [Chatbot Arena](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you're testing the context feature. How can I assist you further? If you have any specific questions or topics you'd like to discuss, feel free to let me know!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "print(call_llm(llm, \"This is a test context\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIM_DJRo9jVN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVFc-lVy9jVN"
      },
      "source": [
        "Now let's generate our QA couples.\n",
        "For this example, we generate only 10 QA couples and will load the rest from the Hub.\n",
        "\n",
        "But for your specific knowledge base, given that you want to get at least ~100 test samples, and accounting for the fact that we will filter out around half of these with our critique agents later on, you should generate much more, in the >200 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 30 QA couples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:41<00:00,  1.38s/it]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "N_GENERATIONS = 10  # keep it low for testing\n",
        "\n",
        "print(f\"Generating {N_GENERATIONS} QA couples...\")\n",
        "\n",
        "outputs = []\n",
        "for sampled_context in tqdm(\n",
        "    random.sample(docs_processed, min(N_GENERATIONS, len(docs_processed)))\n",
        "):\n",
        "    output_QA_couple = call_llm(\n",
        "        llm, QA_generation_prompt.format(context=sampled_context.page_content)\n",
        "    )\n",
        "    try:\n",
        "        question = (\n",
        "            output_QA_couple.split(\"Factoid question: \")[-1]\n",
        "            .split(\"Answer: \")[0]\n",
        "            .strip()\n",
        "        )\n",
        "        answer = output_QA_couple.split(\"Answer: \")[-1].strip()\n",
        "        assert len(answer) < 300, \"Answer is too long\"\n",
        "        outputs.append(\n",
        "            {\n",
        "                \"context\": sampled_context.page_content,\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"source_doc\": sampled_context.metadata.get(\"source\"),\n",
        "            }\n",
        "        )\n",
        "    except Exception:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aUlOUDv59jVN",
        "outputId": "c9634fdb-2a7f-43a6-c4eb-e60b166b8238"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>| Model                                                                                    | Dataset                                                                                                                                                                                           | License            | Use                     |\\n|------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|-------------------------|\\n| [Falcon 40B](https://huggingface.co/tiiuae/falcon-40b)                                   | [Falcon RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)                                                                                                                     | Apache-2.0         | Text Generation         |\\n| [SalesForce XGen 7B](https://huggingface.co/Salesforce/xgen-7b-8k-base)                  | Mix of C4, RedPajama and more                                                                                                                                                                     | Apache-2.0         | Text Generation         |\\n| [MPT-30B](https://huggingface.co/mosaicml/mpt-30b)                                       | Mix of C4, RedPajama and more                                                                                                                                                                     | Apache-2.0         | Text Generation         |</td>\n",
              "      <td>What is the license type for the Falcon 40B model?</td>\n",
              "      <td>Apache-2.0</td>\n",
              "      <td>huggingface/blog/blob/main/os-llms.md</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To load a pretrained model:\\n\\n```py\\n&gt;&gt;&gt; import timm\\n&gt;&gt;&gt; model = timm.create_model('tf_efficientnet_lite0', pretrained=True)\\n&gt;&gt;&gt; model.eval()\\n```\\n\\nTo load and preprocess the image:\\n\\n```py\\n&gt;&gt;&gt; import urllib\\n&gt;&gt;&gt; from PIL import Image\\n&gt;&gt;&gt; from timm.data import resolve_data_config\\n&gt;&gt;&gt; from timm.data.transforms_factory import create_transform\\n\\n&gt;&gt;&gt; config = resolve_data_config({}, model=model)\\n&gt;&gt;&gt; transform = create_transform(**config)\\n\\n&gt;&gt;&gt; url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\\n&gt;&gt;&gt; urllib.request.urlretrieve(url, filename)\\n&gt;&gt;&gt; img = Image.open(filename).convert('RGB')\\n&gt;&gt;&gt; tensor = transform(img).unsqueeze(0) # transform and add batch dimension\\n```\\n\\nTo get the model predictions:\\n\\n```py\\n&gt;&gt;&gt; import torch\\n&gt;&gt;&gt; with torch.no_grad():\\n...     out = model(tensor)\\n&gt;&gt;&gt; probabilities = torch.nn.functional.softmax(out[0], dim=0)\\n&gt;&gt;&gt; print(probabilities.shape)\\n&gt;&gt;&gt; # prints: torch.Size([1000])\\n```\\n\\nTo get the top-5 predictions class names:\\n\\n```py\\n&gt;&gt;&gt; # Get imagenet class mappings\\n&gt;&gt;&gt; url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\\n&gt;&gt;&gt; urllib.request.urlretrieve(url, filename)\\n&gt;&gt;&gt; with open(\"imagenet_classes.txt\", \"r\") as f:\\n...     categories = [s.strip() for s in f.readlines()]\\n\\n&gt;&gt;&gt; # Print top categories per image\\n&gt;&gt;&gt; top5_prob, top5_catid = torch.topk(probabilities, 5)\\n&gt;&gt;&gt; for i in range(top5_prob.size(0)):\\n...     print(categories[top5_catid[i]], top5_prob[i].item())\\n&gt;&gt;&gt; # prints class names and probabilities like:\\n&gt;&gt;&gt; # [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]\\n```\\n\\nReplace the model name with the variant you want to use, e.g. `tf_efficientnet_lite0`. You can find the IDs in the model summaries at the top of this page.</td>\n",
              "      <td>What is the shape of the probabilities tensor after getting model predictions?</td>\n",
              "      <td>torch.Size([1000])</td>\n",
              "      <td>huggingface/pytorch-image-models/blob/main/hfdocs/source/models/tf-efficientnet-lite.mdx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>`column_statistics` content depends on the feature type, see examples below.\\n##### class_label\\n\\n&lt;details&gt;&lt;summary&gt;example: &lt;/summary&gt;\\n&lt;p&gt;\\n\\n```python\\n{\\n    \"column_name\": \"class_col\",\\n    \"column_type\": \"class_label\",\\n    \"column_statistics\": {\\n        \"nan_count\": 0,\\n        \"nan_proportion\": 0.0,\\n        \"no_label_count\": 0,  # number of -1 values - special value of the `datasets` lib to encode `no label` \\n        \"no_label_proportion\": 0.0,\\n        \"n_unique\": 5,  # number of unique values (excluding `no label` and nan)\\n        \"frequencies\": {   # mapping value -&gt; its count\\n            \"this\": 19834,\\n            \"are\": 20159,\\n            \"random\": 20109,\\n            \"words\": 20172,\\n            \"test\": 19726\\n        }\\n    }\\n}\\n```\\n&lt;/p&gt;\\n&lt;/details&gt; \\n\\n##### float\\n\\nBin size for histogram is counted as `(max_value - min_value) / DESCRIPTIVE_STATISTICS_HISTOGRAM_NUM_BINS`\\n\\n&lt;details&gt;&lt;summary&gt;example: &lt;/summary&gt;\\n&lt;p&gt;\\n\\n```python\\n{\\n    \"column_name\": \"delay\",\\n    \"column_type\": \"float\",\\n    \"column_statistics\": {\\n        \"nan_count\": 0,\\n        \"nan_proportion\": 0.0,\\n        \"min\": -10.206,\\n        \"max\": 8.48053,\\n        \"mean\": 2.10174,\\n        \"median\": 3.4012,\\n        \"std\": 3.12487,\\n        \"histogram\": {\\n            \"hist\": [\\n                2,\\n                34,\\n                256,\\n                15198,\\n                9037,\\n                2342,\\n                12743,\\n                45114,\\n                14904,\\n                370\\n            ],\\n            \"bin_edges\": [\\n                -10.206,\\n                -8.33734,\\n                -6.46869,\\n                -4.60004,\\n                -2.73139,\\n                -0.86273,\\n                1.00592,\\n                2.87457,\\n                4.74322,\\n                6.61188,\\n                8.48053  # includes maximum value, so len is always len(hist) + 1\\n            ]\\n        }\\n    }\\n}\\n```\\n&lt;/p&gt;\\n&lt;/details&gt; \\n\\n##### int</td>\n",
              "      <td>What is the maximum value for the column named \"delay\"?</td>\n",
              "      <td>8.48053</td>\n",
              "      <td>huggingface/datasets-server/blob/main/services/worker/README.md</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And, we've released two parts of this course and planning to release the third part this year. I'm really excited about the next part that we're developing right now where we're going to explore different modalities where transformers are really powerful. Most of the time we think of transformers for NLP, but likely there's been this explosion where transformers are being used in things like audio or in computer vision and we're going to be looking at these in detail. \\n\\n### What are some transformers applications that you're excited about? \\n\\n**Lewis:** So one that's kind of fun is in the course we had an event last year where we got people in the community to use the course material to build applications.\\n\\nAnd one of the participants in this event created a cover letter generator for jobs. So the idea is that when you apply for a job there's always this annoying thing you have to write a cover letter and it's always like a bit like you have to be witty. So this guy created a cover letter generator where you provide some information about yourself and then it generates it from that.\\n\\nAnd he actually used that to apply to Hugging Face.\\n\\n### No way?!\\n\\n**Lewis:** He's joining the Big Science team as an intern. So. I mean this is a super cool thing, right? When you learn something and then use that thing to apply which I thought was pretty awesome. \\n\\n### Where do you want to see more ML applications?</td>\n",
              "      <td>What type of generator did a participant create for job applications?</td>\n",
              "      <td>A cover letter generator.</td>\n",
              "      <td>huggingface/blog/blob/main/lewis-tunstall-interview.md</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Weights: https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\\n  Results:\\n  - Task: Image Classification\\n    Dataset: ImageNet\\n    Metrics:\\n      Top 1 Accuracy: 77.37%\\n      Top 5 Accuracy: 93.56%\\n- Name: tv_resnet152\\n  In Collection: ResNet\\n  Metadata:\\n    FLOPs: 14857660416\\n    Parameters: 60190000\\n    File Size: 241530880\\n    Architecture:\\n    - 1x1 Convolution\\n    - Batch Normalization\\n    - Bottleneck Residual Block\\n    - Convolution\\n    - Global Average Pooling\\n    - Max Pooling\\n    - ReLU\\n    - Residual Block\\n    - Residual Connection\\n    - Softmax\\n    Tasks:\\n    - Image Classification\\n    Training Techniques:\\n    - SGD with Momentum\\n    - Weight Decay\\n    Training Data:\\n    - ImageNet\\n    ID: tv_resnet152\\n    LR: 0.1\\n    Epochs: 90\\n    Crop Pct: '0.875'\\n    LR Gamma: 0.1\\n    Momentum: 0.9\\n    Batch Size: 32\\n    Image Size: '224'\\n    LR Step Size: 30\\n    Weight Decay: 0.0001\\n    Interpolation: bilinear\\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/resnet.py#L769\\n  Weights: https://download.pytorch.org/models/resnet152-b121ed2d.pth\\n  Results:\\n  - Task: Image Classification\\n    Dataset: ImageNet\\n    Metrics:\\n      Top 1 Accuracy: 78.32%\\n      Top 5 Accuracy: 94.05%\\n- Name: tv_resnet34\\n  In Collection: ResNet\\n  Metadata:\\n    FLOPs: 4718469120\\n    Parameters: 21800000\\n    File Size: 87306240\\n    Architecture:\\n    - 1x1 Convolution\\n    - Batch Normalization\\n    - Bottleneck Residual Block\\n    - Convolution\\n    - Global Average Pooling\\n    - Max Pooling\\n    - ReLU\\n    - Residual Block\\n    - Residual Connection\\n    - Softmax\\n    Tasks:\\n    - Image Classification\\n    Training Techniques:\\n    - SGD with Momentum\\n    - Weight Decay\\n    Training Data:\\n    - ImageNet\\n    ID: tv_resnet34\\n    LR: 0.1\\n    Epochs: 90\\n    Crop Pct: '0.875'\\n    LR Gamma: 0.1\\n    Momentum: 0.9\\n    Batch Size: 32\\n    Image Size: '224'\\n    LR Step Size: 30\\n    Weight Decay: 0.0001\\n    Interpolation: bilinear</td>\n",
              "      <td>What is the Top 1 Accuracy of the tv_resnet152 model on the ImageNet dataset?</td>\n",
              "      <td>78.32%</td>\n",
              "      <td>huggingface/pytorch-image-models/blob/main/docs/models/resnet.md</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  context  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                     | Model                                                                                    | Dataset                                                                                                                                                                                           | License            | Use                     |\\n|------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|-------------------------|\\n| [Falcon 40B](https://huggingface.co/tiiuae/falcon-40b)                                   | [Falcon RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)                                                                                                                     | Apache-2.0         | Text Generation         |\\n| [SalesForce XGen 7B](https://huggingface.co/Salesforce/xgen-7b-8k-base)                  | Mix of C4, RedPajama and more                                                                                                                                                                     | Apache-2.0         | Text Generation         |\\n| [MPT-30B](https://huggingface.co/mosaicml/mpt-30b)                                       | Mix of C4, RedPajama and more                                                                                                                                                                     | Apache-2.0         | Text Generation         |   \n",
              "1                                                                                                                                    To load a pretrained model:\\n\\n```py\\n>>> import timm\\n>>> model = timm.create_model('tf_efficientnet_lite0', pretrained=True)\\n>>> model.eval()\\n```\\n\\nTo load and preprocess the image:\\n\\n```py\\n>>> import urllib\\n>>> from PIL import Image\\n>>> from timm.data import resolve_data_config\\n>>> from timm.data.transforms_factory import create_transform\\n\\n>>> config = resolve_data_config({}, model=model)\\n>>> transform = create_transform(**config)\\n\\n>>> url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\\n>>> urllib.request.urlretrieve(url, filename)\\n>>> img = Image.open(filename).convert('RGB')\\n>>> tensor = transform(img).unsqueeze(0) # transform and add batch dimension\\n```\\n\\nTo get the model predictions:\\n\\n```py\\n>>> import torch\\n>>> with torch.no_grad():\\n...     out = model(tensor)\\n>>> probabilities = torch.nn.functional.softmax(out[0], dim=0)\\n>>> print(probabilities.shape)\\n>>> # prints: torch.Size([1000])\\n```\\n\\nTo get the top-5 predictions class names:\\n\\n```py\\n>>> # Get imagenet class mappings\\n>>> url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\\n>>> urllib.request.urlretrieve(url, filename)\\n>>> with open(\"imagenet_classes.txt\", \"r\") as f:\\n...     categories = [s.strip() for s in f.readlines()]\\n\\n>>> # Print top categories per image\\n>>> top5_prob, top5_catid = torch.topk(probabilities, 5)\\n>>> for i in range(top5_prob.size(0)):\\n...     print(categories[top5_catid[i]], top5_prob[i].item())\\n>>> # prints class names and probabilities like:\\n>>> # [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]\\n```\\n\\nReplace the model name with the variant you want to use, e.g. `tf_efficientnet_lite0`. You can find the IDs in the model summaries at the top of this page.   \n",
              "2                                                                                           `column_statistics` content depends on the feature type, see examples below.\\n##### class_label\\n\\n<details><summary>example: </summary>\\n<p>\\n\\n```python\\n{\\n    \"column_name\": \"class_col\",\\n    \"column_type\": \"class_label\",\\n    \"column_statistics\": {\\n        \"nan_count\": 0,\\n        \"nan_proportion\": 0.0,\\n        \"no_label_count\": 0,  # number of -1 values - special value of the `datasets` lib to encode `no label` \\n        \"no_label_proportion\": 0.0,\\n        \"n_unique\": 5,  # number of unique values (excluding `no label` and nan)\\n        \"frequencies\": {   # mapping value -> its count\\n            \"this\": 19834,\\n            \"are\": 20159,\\n            \"random\": 20109,\\n            \"words\": 20172,\\n            \"test\": 19726\\n        }\\n    }\\n}\\n```\\n</p>\\n</details> \\n\\n##### float\\n\\nBin size for histogram is counted as `(max_value - min_value) / DESCRIPTIVE_STATISTICS_HISTOGRAM_NUM_BINS`\\n\\n<details><summary>example: </summary>\\n<p>\\n\\n```python\\n{\\n    \"column_name\": \"delay\",\\n    \"column_type\": \"float\",\\n    \"column_statistics\": {\\n        \"nan_count\": 0,\\n        \"nan_proportion\": 0.0,\\n        \"min\": -10.206,\\n        \"max\": 8.48053,\\n        \"mean\": 2.10174,\\n        \"median\": 3.4012,\\n        \"std\": 3.12487,\\n        \"histogram\": {\\n            \"hist\": [\\n                2,\\n                34,\\n                256,\\n                15198,\\n                9037,\\n                2342,\\n                12743,\\n                45114,\\n                14904,\\n                370\\n            ],\\n            \"bin_edges\": [\\n                -10.206,\\n                -8.33734,\\n                -6.46869,\\n                -4.60004,\\n                -2.73139,\\n                -0.86273,\\n                1.00592,\\n                2.87457,\\n                4.74322,\\n                6.61188,\\n                8.48053  # includes maximum value, so len is always len(hist) + 1\\n            ]\\n        }\\n    }\\n}\\n```\\n</p>\\n</details> \\n\\n##### int   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                And, we've released two parts of this course and planning to release the third part this year. I'm really excited about the next part that we're developing right now where we're going to explore different modalities where transformers are really powerful. Most of the time we think of transformers for NLP, but likely there's been this explosion where transformers are being used in things like audio or in computer vision and we're going to be looking at these in detail. \\n\\n### What are some transformers applications that you're excited about? \\n\\n**Lewis:** So one that's kind of fun is in the course we had an event last year where we got people in the community to use the course material to build applications.\\n\\nAnd one of the participants in this event created a cover letter generator for jobs. So the idea is that when you apply for a job there's always this annoying thing you have to write a cover letter and it's always like a bit like you have to be witty. So this guy created a cover letter generator where you provide some information about yourself and then it generates it from that.\\n\\nAnd he actually used that to apply to Hugging Face.\\n\\n### No way?!\\n\\n**Lewis:** He's joining the Big Science team as an intern. So. I mean this is a super cool thing, right? When you learn something and then use that thing to apply which I thought was pretty awesome. \\n\\n### Where do you want to see more ML applications?   \n",
              "4  Weights: https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\\n  Results:\\n  - Task: Image Classification\\n    Dataset: ImageNet\\n    Metrics:\\n      Top 1 Accuracy: 77.37%\\n      Top 5 Accuracy: 93.56%\\n- Name: tv_resnet152\\n  In Collection: ResNet\\n  Metadata:\\n    FLOPs: 14857660416\\n    Parameters: 60190000\\n    File Size: 241530880\\n    Architecture:\\n    - 1x1 Convolution\\n    - Batch Normalization\\n    - Bottleneck Residual Block\\n    - Convolution\\n    - Global Average Pooling\\n    - Max Pooling\\n    - ReLU\\n    - Residual Block\\n    - Residual Connection\\n    - Softmax\\n    Tasks:\\n    - Image Classification\\n    Training Techniques:\\n    - SGD with Momentum\\n    - Weight Decay\\n    Training Data:\\n    - ImageNet\\n    ID: tv_resnet152\\n    LR: 0.1\\n    Epochs: 90\\n    Crop Pct: '0.875'\\n    LR Gamma: 0.1\\n    Momentum: 0.9\\n    Batch Size: 32\\n    Image Size: '224'\\n    LR Step Size: 30\\n    Weight Decay: 0.0001\\n    Interpolation: bilinear\\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/resnet.py#L769\\n  Weights: https://download.pytorch.org/models/resnet152-b121ed2d.pth\\n  Results:\\n  - Task: Image Classification\\n    Dataset: ImageNet\\n    Metrics:\\n      Top 1 Accuracy: 78.32%\\n      Top 5 Accuracy: 94.05%\\n- Name: tv_resnet34\\n  In Collection: ResNet\\n  Metadata:\\n    FLOPs: 4718469120\\n    Parameters: 21800000\\n    File Size: 87306240\\n    Architecture:\\n    - 1x1 Convolution\\n    - Batch Normalization\\n    - Bottleneck Residual Block\\n    - Convolution\\n    - Global Average Pooling\\n    - Max Pooling\\n    - ReLU\\n    - Residual Block\\n    - Residual Connection\\n    - Softmax\\n    Tasks:\\n    - Image Classification\\n    Training Techniques:\\n    - SGD with Momentum\\n    - Weight Decay\\n    Training Data:\\n    - ImageNet\\n    ID: tv_resnet34\\n    LR: 0.1\\n    Epochs: 90\\n    Crop Pct: '0.875'\\n    LR Gamma: 0.1\\n    Momentum: 0.9\\n    Batch Size: 32\\n    Image Size: '224'\\n    LR Step Size: 30\\n    Weight Decay: 0.0001\\n    Interpolation: bilinear   \n",
              "\n",
              "                                                                         question  \\\n",
              "0                              What is the license type for the Falcon 40B model?   \n",
              "1  What is the shape of the probabilities tensor after getting model predictions?   \n",
              "2                         What is the maximum value for the column named \"delay\"?   \n",
              "3           What type of generator did a participant create for job applications?   \n",
              "4   What is the Top 1 Accuracy of the tv_resnet152 model on the ImageNet dataset?   \n",
              "\n",
              "                      answer  \\\n",
              "0                 Apache-2.0   \n",
              "1         torch.Size([1000])   \n",
              "2                    8.48053   \n",
              "3  A cover letter generator.   \n",
              "4                     78.32%   \n",
              "\n",
              "                                                                                 source_doc  \n",
              "0                                                     huggingface/blog/blob/main/os-llms.md  \n",
              "1  huggingface/pytorch-image-models/blob/main/hfdocs/source/models/tf-efficientnet-lite.mdx  \n",
              "2                           huggingface/datasets-server/blob/main/services/worker/README.md  \n",
              "3                                    huggingface/blog/blob/main/lewis-tunstall-interview.md  \n",
              "4                          huggingface/pytorch-image-models/blob/main/docs/models/resnet.md  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(pd.DataFrame(outputs).head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KG4dNtg9jVN"
      },
      "source": [
        "### 1.3. Setup critique agents\n",
        "\n",
        "The questions generated by the previous agent can have many flaws: we should do a quality check before validating these questions.\n",
        "\n",
        "We thus build critique agents that will rate each question on several criteria, given in [this paper](https://huggingface.co/papers/2312.10003):\n",
        "- **Groundedness:** can the question be answered from the given context?\n",
        "- **Relevance:** is the question relevant to users? For instance, `\"What is the date when transformers 4.29.1 was released?\"` is not relevant for ML practitioners.\n",
        "\n",
        "One last failure case we've noticed is when a function is tailored for the particular setting where the question was generated, but undecipherable by itself, like `\"What is the name of the function used in this guide?\"`.\n",
        "We also build a critique agent for this criteria:\n",
        "- **Stand-alone**: is the question understandable free of any context, for someone with domain knowledge/Internet access? The opposite of this would be `What is the function used in this article?` for a question generated from a specific blog article.\n",
        "\n",
        "We systematically score functions with all these agents, and whenever the score is too low for any one of the agents, we eliminate the question from our eval dataset.\n",
        "\n",
        "üí° ___When asking the agents to output a score, we first ask them to produce its rationale. This will help us verify scores, but most importantly, asking it to first output rationale gives the model more tokens to think and elaborate an answer before summarizing it into a single score token.___\n",
        "\n",
        "We now build and run these critique agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05aSgTGs9jVO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b9tbk7ME9jVO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating critique for each QA couple...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [02:23<00:00,  4.77s/it]\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating critique for each QA couple...\")\n",
        "for output in tqdm(outputs):\n",
        "    evaluations = {\n",
        "        \"groundedness\": call_llm(\n",
        "            llm,\n",
        "            question_groundedness_critique_prompt.format(\n",
        "                context=output[\"context\"], question=output[\"question\"]\n",
        "            ),\n",
        "        ),\n",
        "        \"relevance\": call_llm(\n",
        "            llm,\n",
        "            question_relevance_critique_prompt.format(question=output[\"question\"]),\n",
        "        ),\n",
        "        \"standalone\": call_llm(\n",
        "            llm,\n",
        "            question_standalone_critique_prompt.format(question=output[\"question\"]),\n",
        "        ),\n",
        "    }\n",
        "    try:\n",
        "        for criterion, evaluation in evaluations.items():\n",
        "            score, eval = (\n",
        "                int(evaluation.split(\"Total rating: \")[-1].strip()),\n",
        "                evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1],\n",
        "            )\n",
        "            output.update(\n",
        "                {\n",
        "                    f\"{criterion}_score\": score,\n",
        "                    f\"{criterion}_eval\": eval,\n",
        "                }\n",
        "            )\n",
        "    except Exception:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQv36Y_f9jVO"
      },
      "source": [
        "Now let us filter out bad questions based on our critique agent scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oBWuOu1b9jVO",
        "outputId": "b32bacea-52f8-486a-96fe-5c188605c5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation dataset before filtering:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>groundedness_score</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>standalone_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the license type for the Falcon 40B model?</td>\n",
              "      <td>Apache-2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the shape of the probabilities tensor after getting model predictions?</td>\n",
              "      <td>torch.Size([1000])</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the maximum value for the column named \"delay\"?</td>\n",
              "      <td>8.48053</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What type of generator did a participant create for job applications?</td>\n",
              "      <td>A cover letter generator.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the Top 1 Accuracy of the tv_resnet152 model on the ImageNet dataset?</td>\n",
              "      <td>78.32%</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is the model name used in the hyperparameters for training?</td>\n",
              "      <td>facebook/bart-large-cnn</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What method allows you to instantiate a model from a pretrained version?</td>\n",
              "      <td>`from_pretrained()`</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is the purpose of a neural compressor?</td>\n",
              "      <td>To optimize neural network models for efficiency and performance.</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the famous benchmark mentioned for measuring how good models are at question answering?</td>\n",
              "      <td>SQuAD</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How do you configure git to sign your commits with GPG?</td>\n",
              "      <td>Use the command `git config user.signingkey &lt;Your GPG Key ID&gt;` and `git config user.email &lt;Your email on hf.co&gt;`.</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is a recommended resource to understand how Wav2Vec2 works in theory?</td>\n",
              "      <td>Facebook's Wav2Vec2 blog post.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is the sampling rate used for the pretrained Wav2Vec2 model on LibriSpeech and LibriVox?</td>\n",
              "      <td>16kHz</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is the purpose of DebertaV2ForMaskedLM?</td>\n",
              "      <td>It is used for masked language modeling.</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What API is used to deploy models from the fairseq pre-trained model?</td>\n",
              "      <td>torch.hub</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What is the expected shape of the video tensor in the create_gif function?</td>\n",
              "      <td>(num_frames, num_channels, height, width)</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What is the parameter count of the GPT2-XL model used for training on Habana Gaudi?</td>\n",
              "      <td>1.6 billion parameters.</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Who are the authors of the paper titled \"From WER and RIL to MER and WIL: improved evaluation measures for connected speech recognition\"?</td>\n",
              "      <td>Andrew Morris, Viktoria Maier, and Phil Green.</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Who contributed the InstructBLIP model?</td>\n",
              "      <td>nielsr</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What is the title of the paper that proposed the TimeSformer model?</td>\n",
              "      <td>TimeSformer: Is Space-Time Attention All You Need for Video Understanding?</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Who released the Reformer model?</td>\n",
              "      <td>Google Research</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>How much RAM does the 40B model take to run using 4-bit loading?</td>\n",
              "      <td>~27 GB of RAM.</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>How can I contact Hugging Face for help with uploading a large dataset?</td>\n",
              "      <td>You can contact datasets@huggingface.co for help with uploading a large dataset.</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>What is the Top 1 Accuracy of the tf_efficientnet_b5_ns model on the ImageNet dataset?</td>\n",
              "      <td>86.08%</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>What function is used to create a pipeline for accelerated inference with ONNX Runtime?</td>\n",
              "      <td>The `pipeline` function.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>What is the maximum batch size for assisted generation in ü§ó Transformers as of the blog post release?</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>What is the title of the collection created in the context?</td>\n",
              "      <td>OS Week Highlights - Sept 18 - 24</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>What is the drug name associated with the review that mentions \"I have taken Cymbalta for about a year and a half for fibromyalgia pain\"?</td>\n",
              "      <td>Duloxetine</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>What library is being installed in the Gradio demo code?</td>\n",
              "      <td>gradio</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>What command is used to install the `Accelerate` library from Hugging Face?</td>\n",
              "      <td>`pip install git+https://github.com/huggingface/accelerate`</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>How much faster should the assistant model be compared to the main model for optimal performance?</td>\n",
              "      <td>The assistant model should be at least 3x faster than the main model.</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                     question  \\\n",
              "0                                                                                          What is the license type for the Falcon 40B model?   \n",
              "1                                                              What is the shape of the probabilities tensor after getting model predictions?   \n",
              "2                                                                                     What is the maximum value for the column named \"delay\"?   \n",
              "3                                                                       What type of generator did a participant create for job applications?   \n",
              "4                                                               What is the Top 1 Accuracy of the tv_resnet152 model on the ImageNet dataset?   \n",
              "5                                                                            What is the model name used in the hyperparameters for training?   \n",
              "6                                                                    What method allows you to instantiate a model from a pretrained version?   \n",
              "7                                                                                                 What is the purpose of a neural compressor?   \n",
              "8                                             What is the famous benchmark mentioned for measuring how good models are at question answering?   \n",
              "9                                                                                     How do you configure git to sign your commits with GPG?   \n",
              "10                                                                 What is a recommended resource to understand how Wav2Vec2 works in theory?   \n",
              "11                                              What is the sampling rate used for the pretrained Wav2Vec2 model on LibriSpeech and LibriVox?   \n",
              "12                                                                                               What is the purpose of DebertaV2ForMaskedLM?   \n",
              "13                                                                      What API is used to deploy models from the fairseq pre-trained model?   \n",
              "14                                                                 What is the expected shape of the video tensor in the create_gif function?   \n",
              "15                                                        What is the parameter count of the GPT2-XL model used for training on Habana Gaudi?   \n",
              "16  Who are the authors of the paper titled \"From WER and RIL to MER and WIL: improved evaluation measures for connected speech recognition\"?   \n",
              "17                                                                                                    Who contributed the InstructBLIP model?   \n",
              "18                                                                        What is the title of the paper that proposed the TimeSformer model?   \n",
              "19                                                                                                           Who released the Reformer model?   \n",
              "20                                                                           How much RAM does the 40B model take to run using 4-bit loading?   \n",
              "21                                                                    How can I contact Hugging Face for help with uploading a large dataset?   \n",
              "22                                                     What is the Top 1 Accuracy of the tf_efficientnet_b5_ns model on the ImageNet dataset?   \n",
              "23                                                    What function is used to create a pipeline for accelerated inference with ONNX Runtime?   \n",
              "24                                      What is the maximum batch size for assisted generation in ü§ó Transformers as of the blog post release?   \n",
              "25                                                                                What is the title of the collection created in the context?   \n",
              "26  What is the drug name associated with the review that mentions \"I have taken Cymbalta for about a year and a half for fibromyalgia pain\"?   \n",
              "27                                                                                   What library is being installed in the Gradio demo code?   \n",
              "28                                                                What command is used to install the `Accelerate` library from Hugging Face?   \n",
              "29                                          How much faster should the assistant model be compared to the main model for optimal performance?   \n",
              "\n",
              "                                                                                                               answer  \\\n",
              "0                                                                                                          Apache-2.0   \n",
              "1                                                                                                  torch.Size([1000])   \n",
              "2                                                                                                             8.48053   \n",
              "3                                                                                           A cover letter generator.   \n",
              "4                                                                                                              78.32%   \n",
              "5                                                                                             facebook/bart-large-cnn   \n",
              "6                                                                                                 `from_pretrained()`   \n",
              "7                                                   To optimize neural network models for efficiency and performance.   \n",
              "8                                                                                                               SQuAD   \n",
              "9   Use the command `git config user.signingkey <Your GPG Key ID>` and `git config user.email <Your email on hf.co>`.   \n",
              "10                                                                                     Facebook's Wav2Vec2 blog post.   \n",
              "11                                                                                                              16kHz   \n",
              "12                                                                           It is used for masked language modeling.   \n",
              "13                                                                                                          torch.hub   \n",
              "14                                                                          (num_frames, num_channels, height, width)   \n",
              "15                                                                                            1.6 billion parameters.   \n",
              "16                                                                     Andrew Morris, Viktoria Maier, and Phil Green.   \n",
              "17                                                                                                             nielsr   \n",
              "18                                         TimeSformer: Is Space-Time Attention All You Need for Video Understanding?   \n",
              "19                                                                                                    Google Research   \n",
              "20                                                                                                     ~27 GB of RAM.   \n",
              "21                                   You can contact datasets@huggingface.co for help with uploading a large dataset.   \n",
              "22                                                                                                             86.08%   \n",
              "23                                                                                           The `pipeline` function.   \n",
              "24                                                                                                                  1   \n",
              "25                                                                                  OS Week Highlights - Sept 18 - 24   \n",
              "26                                                                                                         Duloxetine   \n",
              "27                                                                                                             gradio   \n",
              "28                                                        `pip install git+https://github.com/huggingface/accelerate`   \n",
              "29                                              The assistant model should be at least 3x faster than the main model.   \n",
              "\n",
              "    groundedness_score  relevance_score  standalone_score  \n",
              "0                    5                4                 2  \n",
              "1                    5                5                 2  \n",
              "2                    5                2                 1  \n",
              "3                    5                1                 1  \n",
              "4                    5                2                 2  \n",
              "5                    5                3                 2  \n",
              "6                    5                5                 3  \n",
              "7                    1                3                 4  \n",
              "8                    5                4                 2  \n",
              "9                    5                2                 5  \n",
              "10                   5                5                 3  \n",
              "11                   5                5                 1  \n",
              "12                   1                5                 4  \n",
              "13                   5                4                 2  \n",
              "14                   5                3                 1  \n",
              "15                   5                3                 2  \n",
              "16                   5                2                 1  \n",
              "17                   5                3                 2  \n",
              "18                   5                3                 2  \n",
              "19                   5                3                 3  \n",
              "20                   5                4                 2  \n",
              "21                   5                4                 2  \n",
              "22                   5                2                 2  \n",
              "23                   5                5                 2  \n",
              "24                   5                4                 1  \n",
              "25                   5                1                 1  \n",
              "26                   5                3                 2  \n",
              "27                   5                3                 1  \n",
              "28                   5                4                 4  \n",
              "29                   5                4                 2  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================\n",
            "Final evaluation dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>groundedness_score</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>standalone_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>What command is used to install the `Accelerate` library from Hugging Face?</td>\n",
              "      <td>`pip install git+https://github.com/huggingface/accelerate`</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                       question  \\\n",
              "28  What command is used to install the `Accelerate` library from Hugging Face?   \n",
              "\n",
              "                                                         answer  \\\n",
              "28  `pip install git+https://github.com/huggingface/accelerate`   \n",
              "\n",
              "    groundedness_score  relevance_score  standalone_score  \n",
              "28                   5                4                 4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "generated_questions = pd.DataFrame.from_dict(outputs)\n",
        "\n",
        "print(\"Evaluation dataset before filtering:\")\n",
        "display(\n",
        "    generated_questions[\n",
        "        [\n",
        "            \"question\",\n",
        "            \"answer\",\n",
        "            \"groundedness_score\",\n",
        "            \"relevance_score\",\n",
        "            \"standalone_score\",\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "generated_questions = generated_questions.loc[\n",
        "    (generated_questions[\"groundedness_score\"] >= 4)\n",
        "    & (generated_questions[\"relevance_score\"] >= 4)\n",
        "    & (generated_questions[\"standalone_score\"] >= 4)\n",
        "]\n",
        "print(\"============================================\")\n",
        "print(\"Final evaluation dataset:\")\n",
        "display(\n",
        "    generated_questions[\n",
        "        [\n",
        "            \"question\",\n",
        "            \"answer\",\n",
        "            \"groundedness_score\",\n",
        "            \"relevance_score\",\n",
        "            \"standalone_score\",\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "\n",
        "eval_dataset = datasets.Dataset.from_pandas(\n",
        "    generated_questions, split=\"train\", preserve_index=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaOMZyu69jVO"
      },
      "source": [
        "Now our synthetic evaluation dataset is complete! We can evaluate different RAG systems on this evaluation dataset.\n",
        "\n",
        "We have generated only a few QA couples here to reduce time and cost. But let's kickstart the next part by loading a pre-generated dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q3RRz4W79jVO"
      },
      "outputs": [],
      "source": [
        "# download the dataset from the hub\n",
        "eval_dataset = datasets.load_dataset(\"m-ric/huggingface_doc_qa_eval\", split=\"train\")\n",
        "\n",
        "# eval_dataset = datasets.load_dataset(\n",
        "#     \"json\",\n",
        "#     data_files=str(save_dir / \"eval_dataset_hf.jsonl\"),\n",
        "#     split=\"train\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets_local/20250914_145157\n"
          ]
        }
      ],
      "source": [
        "# Save ALL datasets\n",
        "save_dir = f\"datasets_local/{datetime.datetime.now():%Y%m%d_%H%M%S}\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# 1. Original corpus (2,647 docs)\n",
        "if \"ds\" in globals():\n",
        "    initial_corpus = [{\"text\": doc[\"text\"], \"source\": doc[\"source\"]} for doc in ds]\n",
        "    write_jsonl(os.path.join(save_dir, \"initial_corpus.jsonl\"), initial_corpus)\n",
        "\n",
        "# 2. Processed/chunked docs\n",
        "if \"docs_processed\" in globals():\n",
        "    write_jsonl(os.path.join(save_dir, \"processed_docs.jsonl\"), docs_processed)\n",
        "\n",
        "# 3. Your generated QA pairs (all 30)\n",
        "if \"outputs\" in globals():\n",
        "    write_jsonl(os.path.join(save_dir, \"qa_generated_all.jsonl\"), outputs)\n",
        "\n",
        "# 4. Your filtered QA pairs (6 that passed)\n",
        "if \"generated_questions\" in globals():\n",
        "    outputs_filtered = generated_questions.to_dict(\"records\")\n",
        "    write_jsonl(os.path.join(save_dir, \"qa_generated_filtered.jsonl\"), outputs_filtered)\n",
        "\n",
        "# 5. The downloaded eval dataset (67 questions)\n",
        "if \"eval_dataset\" in globals():\n",
        "    eval_data = [item for item in eval_dataset]\n",
        "    write_jsonl(os.path.join(save_dir, \"eval_dataset_hf.jsonl\"), eval_data)\n",
        "\n",
        "\n",
        "print(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
