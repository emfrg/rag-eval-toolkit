{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2647/2647 [00:00<00:00, 434720.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 65 eval questions from HuggingFace dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "import datasets\n",
        "from tqdm import tqdm\n",
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Import shared functions\n",
        "from rag_helpers import (\n",
        "    read_jsonl,\n",
        "    load_embeddings,\n",
        "    answer_with_rag,\n",
        "    run_rag_tests,\n",
        "    RAG_PROMPT_TEMPLATE,\n",
        "    EVALUATION_PROMPT\n",
        ")\n",
        "\n",
        "\n",
        "load_dir = \"datasets_local/20250914_145157\"\n",
        "\n",
        "# Load initial corpus\n",
        "ds = read_jsonl(os.path.join(load_dir, \"initial_corpus.jsonl\"))\n",
        "RAW_KNOWLEDGE_BASE = [\n",
        "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
        "    for doc in tqdm(ds)\n",
        "]\n",
        "\n",
        "# Load eval dataset - CHOOSE ONE:\n",
        "\n",
        "# Option 1: Use the HuggingFace dataset with 65 questions (RECOMMENDED)\n",
        "eval_path_hf = os.path.join(load_dir, \"eval_dataset_hf.jsonl\")\n",
        "if os.path.exists(eval_path_hf):\n",
        "    eval_dataset = datasets.Dataset.from_list(read_jsonl(eval_path_hf))\n",
        "    print(f\"Loaded {len(eval_dataset)} eval questions from HuggingFace dataset\")\n",
        "else:\n",
        "    # Download and save for next time\n",
        "    print(\"Downloading HuggingFace eval dataset...\")\n",
        "    eval_dataset = datasets.load_dataset(\"m-ric/huggingface_doc_qa_eval\", split=\"train\")\n",
        "    # Save it for future use\n",
        "    write_jsonl(eval_path_hf, [item for item in eval_dataset])\n",
        "\n",
        "# Option 2: Use your own generated dataset with only 6 questions (NOT RECOMMENDED for evaluation)\n",
        "# eval_path = os.path.join(load_dir, \"qa_filtered.jsonl\")\n",
        "# eval_dataset = datasets.Dataset.from_list(read_jsonl(eval_path))\n",
        "# print(f\"Loaded {len(eval_dataset)} eval questions from generated dataset\")\n",
        "\n",
        "# # Setup LLM\n",
        "# READER_MODEL_NAME = \"gpt-4o-mini\"\n",
        "# READER_LLM = ChatOpenAI(model=READER_MODEL_NAME, temperature=0.1, max_tokens=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiygbqfT9jVP"
      },
      "source": [
        "# 3. Benchmarking the RAG system\n",
        "\n",
        "The RAG system and the evaluation datasets are now ready. The last step is to judge the RAG system's output on this evaluation dataset.\n",
        "\n",
        "To this end, __we setup a judge agent__. âš–ï¸ðŸ¤–\n",
        "\n",
        "Out of [the different RAG evaluation metrics](https://docs.ragas.io/en/latest/concepts/metrics/index.html), we choose to focus only on Answer Correctness since it is the best end-to-end metric of our system's performance.\n",
        "\n",
        "> We use GPT4 as a judge for its empirically good performance, but you could try with other models such as [kaist-ai/prometheus-13b-v1.0](https://huggingface.co/kaist-ai/prometheus-13b-v1.0) or [BAAI/JudgeLM-33B-v1.0](https://huggingface.co/BAAI/JudgeLM-33B-v1.0).\n",
        "\n",
        "ðŸ’¡ _In the evaluation prompt, we give a detailed description each metric on the scale 1-5, as is done in [Prometheus's prompt template](https://huggingface.co/kaist-ai/prometheus-13b-v1.0): this helps the model ground its metric precisely. If instead you give the judge LLM a vague scale to work with, the outputs will not be consistent enough between different examples._\n",
        "\n",
        "ðŸ’¡ _Again, prompting the LLM to output rationale before giving its final score gives it more tokens to help it formalize and elaborate a judgement._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrlMh_ZI9jVP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ae-3KWzK9jVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import SystemMessage\n",
        "\n",
        "\n",
        "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
        "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ia9Mvn859jVP"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "eval_chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "evaluator_name = \"GPT4\"\n",
        "\n",
        "\n",
        "def evaluate_answers(\n",
        "    answer_path: str,\n",
        "    eval_chat_model,\n",
        "    evaluator_name: str,\n",
        "    evaluation_prompt_template: ChatPromptTemplate,\n",
        ") -> None:\n",
        "    \"\"\"Evaluates generated answers. Modifies the given answer file in place for better checkpointing.\"\"\"\n",
        "    answers = []\n",
        "    if os.path.isfile(answer_path):  # load previous generations if they exist\n",
        "        answers = json.load(open(answer_path, \"r\"))\n",
        "\n",
        "    for experiment in tqdm(answers):\n",
        "        if f\"eval_score_{evaluator_name}\" in experiment:\n",
        "            continue\n",
        "\n",
        "        eval_prompt = evaluation_prompt_template.format_messages(\n",
        "            instruction=experiment[\"question\"],\n",
        "            response=experiment[\"generated_answer\"],\n",
        "            reference_answer=experiment[\"true_answer\"],\n",
        "        )\n",
        "        eval_result = eval_chat_model.invoke(eval_prompt)\n",
        "        feedback, score = [\n",
        "            item.strip() for item in eval_result.content.split(\"[RESULT]\")\n",
        "        ]\n",
        "        experiment[f\"eval_score_{evaluator_name}\"] = score\n",
        "        experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n",
        "\n",
        "        with open(answer_path, \"w\") as f:\n",
        "            json.dump(answers, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXH-szLe9jVP"
      },
      "source": [
        "ðŸš€ Let's run the tests and evaluate answers!ðŸ‘‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW2nnvUT9jVQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/pd/9hqpxwh512sfcxn4vlmj89mh0000gn/T/ipykernel_59652/2357794087.py:1: UserWarning: \n",
            "********************************************************************************\n",
            "RAGatouille WARNING: Future Release Notice\n",
            "--------------------------------------------\n",
            "RAGatouille version 0.0.10 will be migrating to a PyLate backend \n",
            "instead of the current Stanford ColBERT backend.\n",
            "PyLate is a fully mature, feature-equivalent backend, that greatly facilitates compatibility.\n",
            "However, please pin version <0.0.10 if you require the Stanford ColBERT backend.\n",
            "********************************************************************************\n",
            "  from ragatouille import RAGPretrainedModel\n"
          ]
        }
      ],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(\"output\"):\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "# Define reader models\n",
        "READER_MODELS = {\n",
        "    \"gpt-4o-mini\": ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1, max_tokens=512),\n",
        "    \"gpt-4o\": ChatOpenAI(model=\"gpt-4o\", temperature=0.1, max_tokens=512),\n",
        "}\n",
        "\n",
        "# Minimal configuration - focus on what matters most\n",
        "CONFIGS = [\n",
        "    {\n",
        "        \"chunk\": 200,\n",
        "        \"reader\": \"gpt-4o-mini\",\n",
        "        \"rerank\": False,\n",
        "        \"embeddings\": \"text-embedding-3-small\",\n",
        "    },\n",
        "    \n",
        "    {\n",
        "        \"chunk\": 200,\n",
        "        \"reader\": \"gpt-4o-mini\",\n",
        "        \"rerank\": True,\n",
        "        \"embeddings\": \"text-embedding-3-small\",\n",
        "    },\n",
        "    # {\n",
        "    #     \"chunk\": 400,\n",
        "    #     \"reader\": \"gpt-4o-mini\",\n",
        "    #     \"rerank\": False,\n",
        "    #     \"embeddings\": \"text-embedding-3-small\",\n",
        "    # },\n",
        "\n",
        "    # {\n",
        "    #     \"chunk\": 400,\n",
        "    #     \"reader\": \"gpt-4o-mini\",\n",
        "    #     \"rerank\": True,\n",
        "    #     \"embeddings\": \"text-embedding-3-small\",\n",
        "    # },\n",
        "\n",
        "    # {\n",
        "    #     \"chunk\": 200,\n",
        "    #     \"reader\": \"gpt-4o\",\n",
        "    #     \"rerank\": False,\n",
        "    #     \"embeddings\": \"text-embedding-3-small\",\n",
        "    # },\n",
        "    # {\n",
        "    #     \"chunk\": 200,\n",
        "    #     \"reader\": \"gpt-4o\",\n",
        "    #     \"rerank\": True,\n",
        "    #     \"embeddings\": \"text-embedding-3-small\",\n",
        "    # },\n",
        "\n",
        "    # {\n",
        "    #     \"chunk\": 400,\n",
        "    #     \"reader\": \"gpt-4o\",\n",
        "    #     \"rerank\": False,\n",
        "    #     \"embeddings\": \"text-embedding-3-small\",\n",
        "    # },\n",
        "    # {\n",
        "    #     \"chunk\": 400,\n",
        "    #     \"reader\": \"gpt-4o\",\n",
        "    #     \"rerank\": True,\n",
        "    #     \"embeddings\": \"text-embedding-3-small\",\n",
        "    # },\n",
        "    # Add these if you want to test reranking with best configs\n",
        "    # {\"chunk\": 200, \"reader\": \"gpt-4o-mini\", \"rerank\": True, \"embeddings\": \"text-embedding-3-small\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Running configuration: chunk:200_embeddings:text-embedding-3-small_rerank:False_reader:gpt-4o-mini\n",
            "============================================================\n",
            "Loading knowledge base embeddings...\n",
            "Index not found, generating it...\n",
            "Processing embedding batch 2...\n",
            "Processing embedding batch 3...\n",
            "Processing embedding batch 4...\n",
            "Processing embedding batch 5...\n",
            "Processing embedding batch 6...\n",
            "Processing embedding batch 7...\n",
            "Processing embedding batch 8...\n",
            "Processing embedding batch 9...\n",
            "Processing embedding batch 10...\n",
            "Processing embedding batch 11...\n",
            "Processing embedding batch 12...\n",
            "Processing embedding batch 13...\n",
            "Processing embedding batch 14...\n",
            "Processing embedding batch 15...\n",
            "Processing embedding batch 16...\n",
            "Processing embedding batch 17...\n",
            "Processing embedding batch 18...\n",
            "Processing embedding batch 19...\n",
            "Processing embedding batch 20...\n",
            "Processing embedding batch 21...\n",
            "Processing embedding batch 22...\n",
            "Processing embedding batch 23...\n",
            "Processing embedding batch 24...\n",
            "Processing embedding batch 25...\n",
            "Processing embedding batch 26...\n",
            "Processing embedding batch 27...\n",
            "Processing embedding batch 28...\n",
            "Processing embedding batch 29...\n",
            "Processing embedding batch 30...\n",
            "Processing embedding batch 31...\n",
            "Processing embedding batch 32...\n",
            "Processing embedding batch 33...\n",
            "Processing embedding batch 34...\n",
            "Processing embedding batch 35...\n",
            "Processing embedding batch 36...\n",
            "Processing embedding batch 37...\n",
            "Processing embedding batch 38...\n",
            "Processing embedding batch 39...\n",
            "Processing embedding batch 40...\n",
            "Processing embedding batch 41...\n",
            "Processing embedding batch 42...\n",
            "Processing embedding batch 43...\n",
            "Processing embedding batch 44...\n",
            "Processing embedding batch 45...\n",
            "Processing embedding batch 46...\n",
            "Processing embedding batch 47...\n",
            "Processing embedding batch 48...\n",
            "Processing embedding batch 49...\n",
            "Processing embedding batch 50...\n",
            "Processing embedding batch 51...\n",
            "Processing embedding batch 52...\n",
            "Processing embedding batch 53...\n",
            "Processing embedding batch 54...\n",
            "Processing embedding batch 55...\n",
            "Processing embedding batch 56...\n",
            "Processing embedding batch 57...\n",
            "Processing embedding batch 58...\n",
            "Processing embedding batch 59...\n",
            "Processing embedding batch 60...\n",
            "Processing embedding batch 61...\n",
            "Processing embedding batch 62...\n",
            "Processing embedding batch 63...\n",
            "Processing embedding batch 64...\n",
            "Processing embedding batch 65...\n",
            "Processing embedding batch 66...\n",
            "Processing embedding batch 67...\n",
            "Processing embedding batch 68...\n",
            "Processing embedding batch 69...\n",
            "Processing embedding batch 70...\n",
            "Processing embedding batch 71...\n",
            "Processing embedding batch 72...\n",
            "Processing embedding batch 73...\n",
            "Processing embedding batch 74...\n",
            "Processing embedding batch 75...\n",
            "Processing embedding batch 76...\n",
            "Processing embedding batch 77...\n",
            "Processing embedding batch 78...\n",
            "Processing embedding batch 79...\n",
            "Processing embedding batch 80...\n",
            "Processing embedding batch 81...\n",
            "Processing embedding batch 82...\n",
            "Processing embedding batch 83...\n",
            "Processing embedding batch 84...\n",
            "Processing embedding batch 85...\n",
            "Processing embedding batch 86...\n",
            "Processing embedding batch 87...\n",
            "Processing embedding batch 88...\n",
            "Processing embedding batch 89...\n",
            "Processing embedding batch 90...\n",
            "Processing embedding batch 91...\n",
            "Processing embedding batch 92...\n",
            "Processing embedding batch 93...\n",
            "Processing embedding batch 94...\n",
            "Processing embedding batch 95...\n",
            "Processing embedding batch 96...\n",
            "Processing embedding batch 97...\n",
            "Processing embedding batch 98...\n",
            "Processing embedding batch 99...\n",
            "Processing embedding batch 100...\n",
            "Processing embedding batch 101...\n",
            "Processing embedding batch 102...\n",
            "Processing embedding batch 103...\n",
            "Processing embedding batch 104...\n",
            "Processing embedding batch 105...\n",
            "Processing embedding batch 106...\n",
            "Processing embedding batch 107...\n",
            "Processing embedding batch 108...\n",
            "Processing embedding batch 109...\n",
            "Processing embedding batch 110...\n",
            "Processing embedding batch 111...\n",
            "Processing embedding batch 112...\n",
            "Processing embedding batch 113...\n",
            "Skipping reranker...\n",
            "Running RAG tests...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [01:49<00:00,  1.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating answers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [03:09<00:00,  2.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Completed: chunk:200_embeddings:text-embedding-3-small_rerank:False_reader:gpt-4o-mini\n",
            "\n",
            "============================================================\n",
            "Running configuration: chunk:200_embeddings:text-embedding-3-small_rerank:True_reader:gpt-4o-mini\n",
            "============================================================\n",
            "Loading knowledge base embeddings...\n",
            "Setting up reranker...\n",
            "[Sep 14, 15:02:25] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running RAG tests...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/65 [00:00<?, ?it/s]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.50s/it]\n",
            "  2%|â–         | 1/65 [00:03<03:51,  3.62s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.05s/it]\n",
            "  3%|â–Ž         | 2/65 [00:06<03:37,  3.44s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n",
            "  5%|â–         | 3/65 [00:10<03:30,  3.39s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.13s/it]\n",
            "  6%|â–Œ         | 4/65 [00:13<03:23,  3.33s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.12s/it]\n",
            "  8%|â–Š         | 5/65 [00:15<02:59,  3.00s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.16s/it]\n",
            "  9%|â–‰         | 6/65 [00:19<03:06,  3.15s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.09s/it]\n",
            " 11%|â–ˆ         | 7/65 [00:22<03:02,  3.15s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.32s/it]\n",
            " 12%|â–ˆâ–        | 8/65 [00:25<02:50,  3.00s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]\n",
            " 14%|â–ˆâ–        | 9/65 [00:30<03:22,  3.61s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.36s/it]\n",
            " 15%|â–ˆâ–Œ        | 10/65 [00:33<03:13,  3.52s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]\n",
            " 17%|â–ˆâ–‹        | 11/65 [00:36<03:09,  3.51s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.76s/it]\n",
            " 18%|â–ˆâ–Š        | 12/65 [00:40<03:01,  3.42s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.13s/it]\n",
            " 20%|â–ˆâ–ˆ        | 13/65 [00:43<02:55,  3.38s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.04s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 14/65 [00:52<04:14,  4.98s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.28s/it]\n",
            " 23%|â–ˆâ–ˆâ–Ž       | 15/65 [00:54<03:35,  4.30s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.20s/it]\n",
            " 25%|â–ˆâ–ˆâ–       | 16/65 [00:57<03:10,  3.89s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.05s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 17/65 [01:00<02:47,  3.48s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.33s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 18/65 [01:04<02:48,  3.58s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.80s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 19/65 [01:07<02:35,  3.39s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.31s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 20/65 [01:09<02:22,  3.16s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.09s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 21/65 [01:12<02:12,  3.02s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.07s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 22/65 [01:15<02:06,  2.95s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.09s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/65 [01:17<01:54,  2.72s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 24/65 [01:22<02:27,  3.59s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 25/65 [01:25<02:14,  3.36s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.33s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/65 [01:28<02:02,  3.13s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.12s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/65 [01:30<01:51,  2.93s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 28/65 [01:33<01:42,  2.77s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 29/65 [01:35<01:36,  2.69s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.36s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 30/65 [01:38<01:39,  2.83s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.08s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/65 [01:41<01:32,  2.71s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 32/65 [01:44<01:31,  2.78s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.60s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 33/65 [01:47<01:30,  2.82s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/65 [01:49<01:26,  2.79s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/65 [01:52<01:21,  2.71s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 36/65 [01:54<01:15,  2.62s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.02s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 37/65 [01:58<01:20,  2.88s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.17s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 38/65 [02:00<01:14,  2.75s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.14s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/65 [02:04<01:21,  3.12s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/65 [02:07<01:15,  3.04s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 41/65 [02:10<01:12,  3.01s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.36s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 42/65 [02:13<01:11,  3.12s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 43/65 [02:16<01:04,  2.94s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.18s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 44/65 [02:19<01:05,  3.11s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.34s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 45/65 [02:23<01:06,  3.30s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.13s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 46/65 [02:26<01:01,  3.26s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/65 [02:29<00:56,  3.12s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.05s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/65 [02:31<00:48,  2.88s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 49/65 [02:35<00:49,  3.10s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.53s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 50/65 [02:38<00:45,  3.03s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.16s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 51/65 [02:41<00:42,  3.00s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 52/65 [02:45<00:43,  3.33s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/65 [02:49<00:42,  3.51s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.32s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 54/65 [02:52<00:36,  3.34s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.13s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/65 [02:55<00:33,  3.30s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 56/65 [02:58<00:28,  3.12s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.10s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 57/65 [03:00<00:23,  2.89s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.31s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 58/65 [03:03<00:20,  2.88s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.18s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 59/65 [03:06<00:17,  2.85s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.13s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/65 [03:08<00:13,  2.69s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.74s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 61/65 [03:11<00:11,  2.82s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.13s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 62/65 [03:14<00:08,  2.88s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.11s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 63/65 [03:17<00:05,  2.71s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.64s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 64/65 [03:22<00:03,  3.64s/it]/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/Users/manolisfrg/Documents/MyCode/dunderscore_ai/advanced-rag/graphrag_demo/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.93s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [03:26<00:00,  3.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating answers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [02:57<00:00,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Completed: chunk:200_embeddings:text-embedding-3-small_rerank:True_reader:gpt-4o-mini\n",
            "\n",
            "============================================================\n",
            "All configurations completed!\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run tests for each configuration\n",
        "for config in CONFIGS:\n",
        "    # Extract configuration parameters\n",
        "    chunk_size = config[\"chunk\"]\n",
        "    reader_name = config[\"reader\"]\n",
        "    rerank = config[\"rerank\"]\n",
        "    embeddings = config[\"embeddings\"]\n",
        "\n",
        "    # Get the reader LLM\n",
        "    reader_llm = READER_MODELS[reader_name]\n",
        "\n",
        "    # Create settings name for output file\n",
        "    settings_name = f\"chunk:{chunk_size}_embeddings:{embeddings.replace('/', '~')}_rerank:{rerank}_reader:{reader_name}\"\n",
        "    output_file_name = f\"output/rag_{settings_name}.json\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running configuration: {settings_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Load embeddings (will use cache if already exists)\n",
        "    print(\"Loading knowledge base embeddings...\")\n",
        "    knowledge_index = load_embeddings(\n",
        "        RAW_KNOWLEDGE_BASE,\n",
        "        chunk_size=chunk_size,\n",
        "        embedding_model_name=embeddings,\n",
        "    )\n",
        "\n",
        "    # Setup reranker if needed\n",
        "    print(\"Setting up reranker...\" if rerank else \"Skipping reranker...\")\n",
        "    reranker = None\n",
        "    if rerank:\n",
        "        reranker = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
        "\n",
        "    # Run RAG tests\n",
        "    print(\"Running RAG tests...\")\n",
        "    run_rag_tests(\n",
        "        eval_dataset=eval_dataset,\n",
        "        llm=reader_llm,\n",
        "        knowledge_index=knowledge_index,\n",
        "        output_file=output_file_name,\n",
        "        reranker=reranker,\n",
        "        verbose=False,\n",
        "        test_settings=settings_name,\n",
        "    )\n",
        "\n",
        "    # Evaluate answers\n",
        "    print(\"Evaluating answers...\")\n",
        "    evaluate_answers(\n",
        "        output_file_name,\n",
        "        eval_chat_model,\n",
        "        evaluator_name,\n",
        "        evaluation_prompt_template,\n",
        "    )\n",
        "\n",
        "    print(f\"âœ“ Completed: {settings_name}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"All configurations completed!\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "Reader Model=gpt-4o-mini<br>Accuracy (%)=%{text}<br>Configuration=%{y}<extra></extra>",
                  "legendgroup": "gpt-4o-mini",
                  "marker": {
                    "color": "#3498db",
                    "pattern": {
                      "shape": ""
                    }
                  },
                  "name": "gpt-4o-mini",
                  "orientation": "h",
                  "showlegend": true,
                  "text": {
                    "bdata": "TuzETuxEUkDZiZ3YiV1SQA==",
                    "dtype": "f8"
                  },
                  "textposition": "outside",
                  "texttemplate": "%{x:.1f}%",
                  "type": "bar",
                  "x": {
                    "bdata": "TuzETuxEUkDZiZ3YiV1SQA==",
                    "dtype": "f8"
                  },
                  "xaxis": "x",
                  "y": [
                    "Chunk 200, gpt-4o-mini, w/ rerank",
                    "Chunk 200, gpt-4o-mini"
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "barmode": "relative",
                "font": {
                  "size": 12
                },
                "height": 480,
                "legend": {
                  "orientation": "v",
                  "title": {
                    "text": "Reader Model"
                  },
                  "tracegroupgap": 0,
                  "x": 1.02,
                  "xanchor": "left",
                  "y": 1,
                  "yanchor": "top"
                },
                "showlegend": true,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>RAG Performance: Chunk Size and Reader Model Comparison</b>"
                },
                "width": 900,
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "range": [
                    0,
                    100
                  ],
                  "ticksuffix": "%",
                  "title": {
                    "text": "Accuracy (%)"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Configuration"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION SUMMARY\n",
            "============================================================\n",
            "                    Configuration Accuracy\n",
            "           Chunk 200, gpt-4o-mini    73.5%\n",
            "Chunk 200, gpt-4o-mini, w/ rerank    73.1%\n",
            "\n",
            "------------------------------------------------------------\n",
            "âœ¨ Best Configuration: Chunk 200, gpt-4o-mini\n",
            "   Accuracy: 73.5%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import json\n",
        "import plotly.express as px\n",
        "import regex as re\n",
        "\n",
        "\n",
        "\n",
        "# Load all results\n",
        "outputs = []\n",
        "for file in glob.glob(\"output/*.json\"):\n",
        "    output = pd.DataFrame(json.load(open(file, \"r\")))\n",
        "    output[\"settings\"] = file\n",
        "    outputs.append(output)\n",
        "\n",
        "result = pd.concat(outputs)\n",
        "\n",
        "# Process scores\n",
        "result[\"eval_score_GPT4\"] = result[\"eval_score_GPT4\"].apply(\n",
        "    lambda x: int(x) if isinstance(x, str) else 1\n",
        ")\n",
        "result[\"eval_score_GPT4\"] = (result[\"eval_score_GPT4\"] - 1) / 4\n",
        "\n",
        "# Calculate average scores\n",
        "average_scores = result.groupby(\"settings\")[\"eval_score_GPT4\"].mean()\n",
        "\n",
        "# Filter to only include configs we actually ran\n",
        "config_files = []\n",
        "for config in CONFIGS:\n",
        "    settings_name = f\"chunk:{config['chunk']}_embeddings:{config['embeddings'].replace('/', '~')}_rerank:{config['rerank']}_reader:{config['reader']}\"\n",
        "    file_pattern = f\"output/rag_{settings_name}.json\"\n",
        "    config_files.append(file_pattern)\n",
        "\n",
        "# Filter average_scores to only include our configs\n",
        "filtered_scores = average_scores[average_scores.index.isin(config_files)]\n",
        "\n",
        "# Convert to percentage\n",
        "scores_percentage = filtered_scores * 100\n",
        "\n",
        "\n",
        "# Create readable labels\n",
        "def create_label(filepath):\n",
        "    \"\"\"Extract readable label from filepath\"\"\"\n",
        "    # Extract components from filename\n",
        "    import re\n",
        "\n",
        "    pattern = r\"chunk:(\\d+)_embeddings:([^_]+)_rerank:(\\w+)_reader:([^.]+)\"\n",
        "    match = re.search(pattern, filepath)\n",
        "\n",
        "    if match:\n",
        "        chunk, embeddings, rerank, reader = match.groups()\n",
        "        # Create concise label\n",
        "        rerank_str = \"w/ rerank\" if rerank == \"True\" else \"\"\n",
        "        return f\"Chunk {chunk}, {reader}{', ' + rerank_str if rerank_str else ''}\"\n",
        "    return filepath\n",
        "\n",
        "\n",
        "# Create DataFrame for plotting\n",
        "df_plot = pd.DataFrame(\n",
        "    {\n",
        "        \"Configuration\": [create_label(idx) for idx in scores_percentage.index],\n",
        "        \"Accuracy\": scores_percentage.values,\n",
        "        \"Chunk Size\": [\n",
        "            int(re.search(r\"chunk:(\\d+)\", idx).group(1))\n",
        "            for idx in scores_percentage.index\n",
        "        ],\n",
        "        \"Reader Model\": [\n",
        "            re.search(r\"reader:([^.]+)\", idx).group(1)\n",
        "            for idx in scores_percentage.index\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Sort by accuracy for better visualization\n",
        "df_plot = df_plot.sort_values(\"Accuracy\", ascending=True)\n",
        "\n",
        "# Create grouped bar chart\n",
        "fig = px.bar(\n",
        "    df_plot,\n",
        "    x=\"Accuracy\",\n",
        "    y=\"Configuration\",\n",
        "    orientation=\"h\",\n",
        "    color=\"Reader Model\",\n",
        "    text=\"Accuracy\",\n",
        "    title=\"<b>RAG Performance: Chunk Size and Reader Model Comparison</b>\",\n",
        "    labels={\"Accuracy\": \"Accuracy (%)\"},\n",
        "    color_discrete_map={\"gpt-4o-mini\": \"#3498db\", \"gpt-4o\": \"#e74c3c\"},\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=900,\n",
        "    height=400 + len(df_plot) * 40,  # Dynamic height based on number of configs\n",
        "    xaxis_range=[0, 100],\n",
        "    xaxis=dict(ticksuffix=\"%\"),\n",
        "    font=dict(size=12),\n",
        "    showlegend=True,\n",
        "    legend=dict(\n",
        "        title=\"Reader Model\",\n",
        "        orientation=\"v\",\n",
        "        yanchor=\"top\",\n",
        "        y=1,\n",
        "        xanchor=\"left\",\n",
        "        x=1.02,\n",
        "    ),\n",
        ")\n",
        "\n",
        "fig.update_traces(texttemplate=\"%{x:.1f}%\", textposition=\"outside\")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EVALUATION SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "summary_df = df_plot[[\"Configuration\", \"Accuracy\"]].copy()\n",
        "summary_df[\"Accuracy\"] = summary_df[\"Accuracy\"].apply(lambda x: f\"{x:.1f}%\")\n",
        "summary_df = summary_df.sort_values(\"Configuration\")\n",
        "\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Find best configuration\n",
        "best_config = df_plot.loc[df_plot[\"Accuracy\"].idxmax()]\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(f\"âœ¨ Best Configuration: {best_config['Configuration']}\")\n",
        "print(f\"   Accuracy: {best_config['Accuracy']:.1f}%\")\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
